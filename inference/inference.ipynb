{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/bodza/Audio_Dataset/hf_cache/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bodza/miniconda3/envs/xcodec/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TTS process with base 1B and German fine-tuned 1B models...\n",
      "Loading base 1B model...\n",
      "Base 1B model loaded\n",
      "Loading German fine-tuned 1B model...\n",
      "German fine-tuned model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xcodec2 to instantiate a model of type xcodec. This is not supported for all configurations of models and can yield errors.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XCodec2 model loaded\n",
      "\n",
      "Generating speech using Base 1B model...\n",
      "Number of speech tokens generated: 1916\n",
      "Number of speech IDs extracted: 1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for Base 1B model: 31.55 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 613120])\n",
      "\n",
      "Generating speech using German fine-tuned 1B model...\n",
      "Number of speech tokens generated: 1039\n",
      "Number of speech IDs extracted: 1039\n",
      "Generation time for German fine-tuned 1B model: 17.17 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 332480])\n",
      "\n",
      "Saving generated audio files...\n",
      "Process completed! Generated files: gen_base_1b.wav and gen_german_ft.wav\n",
      "\n",
      "You can now compare:\n",
      "1. gen_base_1b.wav - Generated by the base 1B model\n",
      "2. gen_german_ft.wav - Generated by the German fine-tuned model\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print(os.environ[\"HF_HOME\"])\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import time\n",
    "\n",
    "print(\"Starting TTS process with base 1B and German fine-tuned 1B models...\")\n",
    "\n",
    "# Load both models\n",
    "llasa_1b_base = 'HKUSTAudio/Llasa-1B'\n",
    "llasa_1b_german = '/media/bodza/Audio_Dataset/Llasa-Kartoffel-1B-v0.2'  # German fine-tuned model\n",
    "\n",
    "print(\"Loading base 1B model...\")\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(llasa_1b_base)\n",
    "model_base = AutoModelForCausalLM.from_pretrained(llasa_1b_base, cache_dir=\"/media/bodza/Audio_Dataset/hf_cache/hub/models--HKUSTAudio--Llasa-1B\")\n",
    "model_base.eval()\n",
    "model_base.to('cuda')\n",
    "print(\"Base 1B model loaded\")\n",
    "\n",
    "print(\"Loading German fine-tuned 1B model...\")\n",
    "tokenizer_german = AutoTokenizer.from_pretrained(llasa_1b_german)\n",
    "model_german = AutoModelForCausalLM.from_pretrained(llasa_1b_german)\n",
    "model_german.eval()\n",
    "model_german.to('cuda')\n",
    "print(\"German fine-tuned model loaded\")\n",
    "\n",
    "# Load XCodec2 model\n",
    "from xcodec2.modeling_xcodec2 import XCodec2Model\n",
    "model_path = \"HKUST-Audio/xcodec2\"\n",
    "Codec_model = XCodec2Model.from_pretrained(model_path)\n",
    "Codec_model.eval().cuda()\n",
    "print(\"XCodec2 model loaded\")\n",
    "\n",
    "input_text = 'Über sieben Brücken musst du gehen. Sieben dunkle Jahre überstehen. Sieben Mal wirst du die Asche sein. Aber einmal auch der helle Schein. Über sieben Brücken musst du gehen. Sieben dunkle Jahre überstehen. Sieben Mal wirst du die Asche sein. Aber einmal auch der helle Schein. Über sieben Brücken musst du'\n",
    "\n",
    "def ids_to_speech_tokens(speech_ids):\n",
    "    speech_tokens_str = []\n",
    "    for speech_id in speech_ids:\n",
    "        speech_tokens_str.append(f\"<|s_{speech_id}|>\")\n",
    "    return speech_tokens_str\n",
    "\n",
    "def extract_speech_ids(speech_tokens_str):\n",
    "    speech_ids = []\n",
    "    for token_str in speech_tokens_str:\n",
    "        if token_str.startswith('<|s_') and token_str.endswith('|>'):\n",
    "            num_str = token_str[4:-2]\n",
    "            num = int(num_str)\n",
    "            speech_ids.append(num)\n",
    "        else:\n",
    "            print(f\"Unexpected token: {token_str}\")\n",
    "    return speech_ids\n",
    "\n",
    "def generate_speech(model, tokenizer, input_text, model_name):\n",
    "    print(f\"\\nGenerating speech using {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        formatted_text = f\"<|TEXT_UNDERSTANDING_START|>{input_text}<|TEXT_UNDERSTANDING_END|>\"\n",
    "        \n",
    "        chat = [\n",
    "            {\"role\": \"user\", \"content\": \"Convert the text to speech:\" + formatted_text},\n",
    "            {\"role\": \"assistant\", \"content\": \"<|SPEECH_GENERATION_START|>\"}\n",
    "        ]\n",
    "\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            chat,\n",
    "            tokenize=True,\n",
    "            return_tensors='pt',\n",
    "            continue_final_message=True\n",
    "        )\n",
    "        input_ids = input_ids.to('cuda')\n",
    "        speech_end_id = tokenizer.convert_tokens_to_ids('<|SPEECH_GENERATION_END|>')\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_length=2048,\n",
    "            eos_token_id=speech_end_id,\n",
    "            do_sample=True,\n",
    "            top_p=1,\n",
    "            temperature=0.8,\n",
    "        )\n",
    "\n",
    "        generated_ids = outputs[0][input_ids.shape[1]:-1]\n",
    "        speech_tokens = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        print(f\"Number of speech tokens generated: {len(speech_tokens)}\")\n",
    "        \n",
    "        speech_tokens = extract_speech_ids(speech_tokens)\n",
    "        print(f\"Number of speech IDs extracted: {len(speech_tokens)}\")\n",
    "        \n",
    "        speech_tokens = torch.tensor(speech_tokens).cuda().unsqueeze(0).unsqueeze(0)\n",
    "        gen_wav = Codec_model.decode_code(speech_tokens)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Generation time for {model_name}: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Generated waveform shape: {gen_wav.shape}\")\n",
    "        \n",
    "        return gen_wav\n",
    "\n",
    "# Generate speech using both models\n",
    "gen_wav_base = generate_speech(model_base, tokenizer_base, input_text, \"Base 1B model\")\n",
    "gen_wav_german = generate_speech(model_german, tokenizer_german, input_text, \"German fine-tuned 1B model\")\n",
    "\n",
    "# Save both generated audio files\n",
    "print(\"\\nSaving generated audio files...\")\n",
    "sf.write(\"gen_base_1b.wav\", gen_wav_base[0, 0, :].cpu().numpy(), 16000)\n",
    "sf.write(\"gen_german_ft.wav\", gen_wav_german[0, 0, :].cpu().numpy(), 16000)\n",
    "\n",
    "print(\"Process completed! Generated files: gen_base_1b.wav and gen_german_ft.wav\")\n",
    "print(\"\\nYou can now compare:\")\n",
    "print(\"1. gen_base_1b.wav - Generated by the base 1B model\")\n",
    "print(\"2. gen_german_ft.wav - Generated by the German fine-tuned model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Generating sample 1:\n",
      "Text: Essigsäureethylester, auch Ethylacetat oder kurz Essigester, ist eine chemische Verbindung aus der G...\n",
      "\n",
      "Generating speech using Base 1B model - Sample 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speech tokens generated: 968\n",
      "Number of speech IDs extracted: 968\n",
      "Generation time for Base 1B model - Sample 1: 15.71 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 309760])\n",
      "\n",
      "Generating speech using German fine-tuned model - Sample 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speech tokens generated: 787\n",
      "Number of speech IDs extracted: 787\n",
      "Generation time for German fine-tuned model - Sample 1: 13.45 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 251840])\n",
      "\n",
      "Saving audio files for sample 1...\n",
      "Generated files:\n",
      "- sample_1_base_1b.wav\n",
      "- sample_1_german_ft.wav\n",
      "\n",
      "==================================================\n",
      "Generating sample 2:\n",
      "Text: DeepSeek ist ein chinesisches KI-Startup, das sich auf die Entwicklung fortschrittlicher Sprachmodel...\n",
      "\n",
      "Generating speech using Base 1B model - Sample 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speech tokens generated: 1088\n",
      "Number of speech IDs extracted: 1088\n",
      "Generation time for Base 1B model - Sample 2: 18.60 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 348160])\n",
      "\n",
      "Generating speech using German fine-tuned model - Sample 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speech tokens generated: 1430\n",
      "Number of speech IDs extracted: 1430\n",
      "Generation time for German fine-tuned model - Sample 2: 24.17 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 457600])\n",
      "\n",
      "Saving audio files for sample 2...\n",
      "Generated files:\n",
      "- sample_2_base_1b.wav\n",
      "- sample_2_german_ft.wav\n",
      "\n",
      "==================================================\n",
      "Generating sample 3:\n",
      "Text: Guten Morgen! Wie geht es dir heute? Das Wetter ist wunderschön. Lass uns spazieren gehen....\n",
      "\n",
      "Generating speech using Base 1B model - Sample 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speech tokens generated: 367\n",
      "Number of speech IDs extracted: 367\n",
      "Generation time for Base 1B model - Sample 3: 6.37 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 117440])\n",
      "\n",
      "Generating speech using German fine-tuned model - Sample 3...\n",
      "Number of speech tokens generated: 335\n",
      "Number of speech IDs extracted: 335\n",
      "Generation time for German fine-tuned model - Sample 3: 6.52 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 107200])\n",
      "\n",
      "Saving audio files for sample 3...\n",
      "Generated files:\n",
      "- sample_3_base_1b.wav\n",
      "- sample_3_german_ft.wav\n",
      "\n",
      "All samples generated successfully!\n",
      "\n",
      "Generated files summary:\n",
      "\n",
      "Sample 1:\n",
      "- sample_1_base_1b.wav (Base 1B model)\n",
      "- sample_1_german_ft.wav (German fine-tuned model)\n",
      "\n",
      "Sample 2:\n",
      "- sample_2_base_1b.wav (Base 1B model)\n",
      "- sample_2_german_ft.wav (German fine-tuned model)\n",
      "\n",
      "Sample 3:\n",
      "- sample_3_base_1b.wav (Base 1B model)\n",
      "- sample_3_german_ft.wav (German fine-tuned model)\n"
     ]
    }
   ],
   "source": [
    "# Follow-up cell for additional generations\n",
    "\n",
    "# Different text samples\n",
    "text_samples = [\n",
    "    \"Essigsäureethylester, auch Ethylacetat oder kurz Essigester, ist eine chemische Verbindung aus der Gruppe der Carbonsäureester. Es ist der Ester, der aus Essigsäure und Ethanol gebildet wird. Es handelt sich um eine farblose, flüchtige Flüssigkeit mit charakteristischem Geruch.\",\n",
    "    \"DeepSeek ist ein chinesisches KI-Startup, das sich auf die Entwicklung fortschrittlicher Sprachmodelle und künstlicher Intelligenz spezialisiert hat. Das Unternehmen gewann internationale Aufmerksamkeit mit der Veröffentlichung seines im Januar 2025 vorgestellten Modells DeepSeek R1, das mit etablierten KI-Systemen wie ChatGPT von OpenAI und Claude von Anthropic konkurriert\",\n",
    "    \"Guten Morgen! Wie geht es dir heute? Das Wetter ist wunderschön. Lass uns spazieren gehen.\"\n",
    "]\n",
    "\n",
    "# Generate audio for each text sample with both models\n",
    "for i, text in enumerate(text_samples, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Generating sample {i}:\")\n",
    "    print(f\"Text: {text[:100]}...\")\n",
    "    \n",
    "    # Generate with base model\n",
    "    gen_wav_base = generate_speech(\n",
    "        model_base, \n",
    "        tokenizer_base, \n",
    "        text, \n",
    "        f\"Base 1B model - Sample {i}\"\n",
    "    )\n",
    "    \n",
    "    # Generate with German fine-tuned model\n",
    "    gen_wav_german = generate_speech(\n",
    "        model_german, \n",
    "        tokenizer_german, \n",
    "        text, \n",
    "        f\"German fine-tuned model - Sample {i}\"\n",
    "    )\n",
    "    \n",
    "    # Save the audio files with numbered suffixes\n",
    "    base_filename = f\"sample_{i}_base_1b.wav\"\n",
    "    german_filename = f\"sample_{i}_german_ft.wav\"\n",
    "    \n",
    "    print(f\"\\nSaving audio files for sample {i}...\")\n",
    "    sf.write(base_filename, gen_wav_base[0, 0, :].cpu().numpy(), 16000)\n",
    "    sf.write(german_filename, gen_wav_german[0, 0, :].cpu().numpy(), 16000)\n",
    "    \n",
    "    print(f\"Generated files:\")\n",
    "    print(f\"- {base_filename}\")\n",
    "    print(f\"- {german_filename}\")\n",
    "\n",
    "print(\"\\nAll samples generated successfully!\")\n",
    "print(\"\\nGenerated files summary:\")\n",
    "for i in range(1, len(text_samples) + 1):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"- sample_{i}_base_1b.wav (Base 1B model)\")\n",
    "    print(f\"- sample_{i}_german_ft.wav (German fine-tuned model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Generating sample 1:\n",
      "Text: Actros ist die Bezeichnung für eine Lkw-Baureihe der Marke Mercedes-Benz der Daimler Truck AG. Sie w...\n",
      "\n",
      "Generating speech using Base 1B model - Sample 1...\n",
      "Number of speech tokens generated: 1872\n",
      "Number of speech IDs extracted: 1872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128261 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for Base 1B model - Sample 1: 31.06 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 599040])\n",
      "\n",
      "Generating speech using German fine-tuned model - Sample 1...\n",
      "Number of speech tokens generated: 1253\n",
      "Number of speech IDs extracted: 1253\n",
      "Generation time for German fine-tuned model - Sample 1: 23.32 seconds\n",
      "Generated waveform shape: torch.Size([1, 1, 400960])\n",
      "\n",
      "Saving audio files for sample 1...\n",
      "Generated files:\n",
      "- sample_1_base_1b.wav\n",
      "- sample_1_german_ft.wav\n",
      "\n",
      "All samples generated successfully!\n",
      "\n",
      "Generated files summary:\n",
      "\n",
      "Sample 1:\n",
      "- sample_1_base_1b.wav (Base 1B model)\n",
      "- sample_1_german_ft.wav (German fine-tuned model)\n"
     ]
    }
   ],
   "source": [
    "# Follow-up cell for additional generations\n",
    "\n",
    "# Different text samples\n",
    "text_samples = [\n",
    "    # \"Als Anna abends aß, aß Anna abends Ananas. Brautkleid bleibt Brautkleid und Blaukraut bleibt Blaukraut. Fischers Fritze fischte frische Fische, frische Fische fischte Fischers Fritze. Im dichten Fichtendickicht nicken dicke Fichten tüchtig. Kleine Kinder können keine Kirschkerne knacken.\"\n",
    "\"Actros ist die Bezeichnung für eine Lkw-Baureihe der Marke Mercedes-Benz der Daimler Truck AG. Sie wurde als Nachfolger der Schweren Klasse (SK) auf der IAA Nutzfahrzeuge 1996 eingeführt und daher anfänglich auch als Schwere Klasse Neu, kurz SKN, bezeichnet. In den Jahren 2003 und 2008 gab es umfangreiche Modellpflegemaßnahmen, die auch als MP 2 bzw. MP 3 (Modellprojekt 2 bzw. 3) bekannt sind.\"\n",
    "]\n",
    "\n",
    "# Generate audio for each text sample with both models\n",
    "for i, text in enumerate(text_samples, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Generating sample {i}:\")\n",
    "    print(f\"Text: {text[:100]}...\")\n",
    "    \n",
    "    # Generate with base model\n",
    "    gen_wav_base = generate_speech(\n",
    "        model_base, \n",
    "        tokenizer_base, \n",
    "        text, \n",
    "        f\"Base 1B model - Sample {i}\"\n",
    "    )\n",
    "    \n",
    "    # Generate with German fine-tuned model\n",
    "    gen_wav_german = generate_speech(\n",
    "        model_german, \n",
    "        tokenizer_german, \n",
    "        text, \n",
    "        f\"German fine-tuned model - Sample {i}\"\n",
    "    )\n",
    "    \n",
    "    # Save the audio files with numbered suffixes\n",
    "    base_filename = f\"sample_{i}_base_1b.wav\"\n",
    "    german_filename = f\"sample_{i}_german_ft.wav\"\n",
    "    \n",
    "    print(f\"\\nSaving audio files for sample {i}...\")\n",
    "    sf.write(base_filename, gen_wav_base[0, 0, :].cpu().numpy(), 16000)\n",
    "    sf.write(german_filename, gen_wav_german[0, 0, :].cpu().numpy(), 16000)\n",
    "    \n",
    "    print(f\"Generated files:\")\n",
    "    print(f\"- {base_filename}\")\n",
    "    print(f\"- {german_filename}\")\n",
    "\n",
    "print(\"\\nAll samples generated successfully!\")\n",
    "print(\"\\nGenerated files summary:\")\n",
    "for i in range(1, len(text_samples) + 1):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"- sample_{i}_base_1b.wav (Base 1B model)\")\n",
    "    print(f\"- sample_{i}_german_ft.wav (German fine-tuned model)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcodec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
